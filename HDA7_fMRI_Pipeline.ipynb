{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DyvxdoBwH2iW"
      },
      "source": [
        " ## HDA-7: fMRI Functional Connectivity Feature Extraction\n",
        " This script:\n",
        " - (Optionally) downloads an OpenNeuro dataset (ds002785) via DataLad\n",
        " - Runs fMRIPrep via Docker (manual command provided)\n",
        " - Extracts ROI timeseries, computes connectivity metrics (Nilearn + NetworkX)\n",
        " - Saves a `secondary_dataset.csv`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7rSpY7u5H0qm"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import subprocess\n",
        "import glob\n",
        "import warnings\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from nilearn.maskers import NiftiLabelsMasker\n",
        "from nilearn import datasets\n",
        "from nilearn.connectome import ConnectivityMeasure\n",
        "import networkx as nx\n",
        "\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# ========== 1) Install lightweight Python deps ==========\n",
        "def install_requirements():\n",
        "    try:\n",
        "        subprocess.run(\n",
        "            [\"pip\", \"install\", \"--quiet\", \"nilearn\", \"nibabel\", \"numpy\", \"pandas\", \"networkx\", \"scikit-learn\", \"tqdm\"],\n",
        "            check=True\n",
        "        )\n",
        "    except Exception as e:\n",
        "        print(\"Error installing packages:\", e)\n",
        "    subprocess.run([\"docker\", \"--version\"], check=False)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-QE8qo2uIFht"
      },
      "source": [
        "## Downloading the OpenNeuro Dataset\n",
        "\n",
        "> If you already have the dataset locally, skip this cell and set `BIDS_DIR` to your path.\\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4yY4eeDwIA-W"
      },
      "outputs": [],
      "source": [
        "# ========== 2) Download ds002785 from OpenNeuro ==========\n",
        "def download_dataset():\n",
        "    # Requires datalad installed in system\n",
        "    # subprocess.run([\"pip\", \"install\", \"datalad\"], check=True)\n",
        "    subprocess.run(\n",
        "        [\"datalad\", \"install\", \"-s\", \"https://github.com/OpenNeuroDatasets/ds002785\", \"ds002785\"],\n",
        "        check=False\n",
        "    )\n",
        "    subprocess.run([\"ls\", \"-la\", \"ds002785\"], check=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AYwGccLSIVjx"
      },
      "source": [
        "## Running fMRIPrep for pre-processing in Docker"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UWjbT3WFIN_G"
      },
      "outputs": [],
      "source": [
        "# ========== 3) fMRIPrep command (Docker) ==========\n",
        "def print_fmriprep_command(BIDS_DIR, OUT_DIR, WORK_DIR, FS_LICENSE, PARTICIPANTS):\n",
        "    participant_flag = ''\n",
        "    if len(PARTICIPANTS) > 0:\n",
        "        participant_flag = '--participant-label ' + ' '.join(PARTICIPANTS)\n",
        "    cmd = (\n",
        "        f\"docker run --rm -it \"\n",
        "        f\"-v {BIDS_DIR}:/data:ro \"\n",
        "        f\"-v {OUT_DIR}:/out \"\n",
        "        f\"-v {WORK_DIR}:/work \"\n",
        "        f\"-v {FS_LICENSE}:/opt/freesurfer/license.txt \"\n",
        "        f\"nipreps/fmriprep:stable /data /out participant {participant_flag} \"\n",
        "        f\"--fs-license-file /opt/freesurfer/license.txt \"\n",
        "        f\"--output-spaces MNI152NLin2009cAsym:res-2 --use-aroma --skip-bids-validation\"\n",
        "    )\n",
        "\n",
        "    print(cmd)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oas5lmquIg18"
      },
      "source": [
        "## Extracting features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A-PtMqKxIbQR"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n",
        "# ========== 4) Feature extraction ==========\n",
        "def extract_features(BIDS_DIR, DERIV_DIR, SPACE):\n",
        "    participants_tsv = os.path.join(BIDS_DIR, 'participants.tsv')\n",
        "    if not os.path.exists(participants_tsv):\n",
        "        raise FileNotFoundError(f'participants.tsv not found at {participants_tsv}')\n",
        "    pheno = pd.read_csv(participants_tsv, sep='\\t')\n",
        "\n",
        "    label_col = None\n",
        "    for c in ['diagnosis','label','group','social_anxiety','social_anxiety_diagnosis','clinical_diagnosis']:\n",
        "        if c in pheno.columns:\n",
        "            label_col = c\n",
        "            break\n",
        "    if label_col is None:\n",
        "        print(\"Warning: could not auto-detect label column. Using dummy 'Control' labels.\")\n",
        "        pheno['Label'] = 'Control'\n",
        "        label_col = 'Label'\n",
        "\n",
        "    ho_cort = datasets.fetch_atlas_harvard_oxford('cort-maxprob-thr25-2mm')\n",
        "    ho_subc = datasets.fetch_atlas_harvard_oxford('sub-maxprob-thr25-2mm')\n",
        "    masker_cort = NiftiLabelsMasker(ho_cort.maps, standardize=True, detrend=True)\n",
        "    masker_subc = NiftiLabelsMasker(ho_subc.maps, standardize=True, detrend=True)\n",
        "\n",
        "    def find_preproc_bold(sub):\n",
        "        pattern = os.path.join(DERIV_DIR, f'sub-{sub}', 'func', f'sub-{sub}_*{SPACE}*_desc-preproc_bold.nii.gz')\n",
        "        return sorted(glob.glob(pattern))\n",
        "\n",
        "    def labels_to_index_map(labels):\n",
        "        return { (lbl.decode() if isinstance(lbl, bytes) else lbl): i for i,lbl in enumerate(labels) }\n",
        "\n",
        "    cort_labels = labels_to_index_map(ho_cort.labels)\n",
        "    subc_labels = labels_to_index_map(ho_subc.labels)\n",
        "\n",
        "    def find_indices_by_names(mapping, names):\n",
        "        idx = []\n",
        "        for n in names:\n",
        "            matches = [v for k,v in mapping.items() if n.lower() in k.lower()]\n",
        "            idx.extend(matches)\n",
        "        return sorted(set(idx))\n",
        "\n",
        "    amyg_idx = find_indices_by_names(subc_labels, ['Amygdala'])\n",
        "    pfc_idx  = find_indices_by_names(cort_labels, ['Frontal Pole','Frontal Medial','Superior Frontal','Middle Frontal','Orbital'])\n",
        "    acc_idx  = find_indices_by_names(cort_labels, ['Anterior Cingulate'])\n",
        "    pcc_idx  = find_indices_by_names(cort_labels, ['Posterior Cingulate'])\n",
        "    mpfc_idx = find_indices_by_names(cort_labels, ['Frontal Medial','Frontal Pole','Superior Frontal Medial'])\n",
        "\n",
        "    print('ROIs found (counts):', 'amyg', len(amyg_idx), 'pfc', len(pfc_idx), 'acc', len(acc_idx), 'pcc', len(pcc_idx), 'mpfc', len(mpfc_idx))\n",
        "\n",
        "    subjects = [p.replace('sub-','') for p in pheno['participant_id'].astype(str)] if 'participant_id' in pheno.columns \\\n",
        "               else [r.split('_')[0].replace('sub-','') for r in os.listdir(DERIV_DIR) if r.startswith('sub-')]\n",
        "\n",
        "    rows = []\n",
        "    conn_estimator = ConnectivityMeasure(kind='correlation')\n",
        "\n",
        "    for sub in subjects:\n",
        "        bolds = find_preproc_bold(sub)\n",
        "        if len(bolds) == 0:\n",
        "            print(f'No preproc bold found for sub-{sub} - skipping')\n",
        "            continue\n",
        "        bold = bolds[0]\n",
        "        conf_path = bold.replace('desc-preproc_bold.nii.gz','desc-confounds_regressors.tsv')\n",
        "        confounds = None\n",
        "        if os.path.exists(conf_path):\n",
        "            try:\n",
        "                confounds = pd.read_csv(conf_path, sep='\\t')\n",
        "            except Exception:\n",
        "                confounds = None\n",
        "        try:\n",
        "            ts_cort = masker_cort.fit_transform(bold, confounds=confounds)\n",
        "            ts_subc = masker_subc.fit_transform(bold, confounds=confounds)\n",
        "        except Exception as e:\n",
        "            print('Error extracting timeseries for', sub, e)\n",
        "            continue\n",
        "\n",
        "        def avg_signal(ts, idx_list):\n",
        "            if len(idx_list) == 0:\n",
        "                return None\n",
        "            return np.nanmean(ts[:, idx_list], axis=1)\n",
        "\n",
        "        amyg_signal = avg_signal(ts_subc, amyg_idx) if amyg_idx else None\n",
        "        pfc_signal  = avg_signal(ts_cort, pfc_idx)  if pfc_idx else None\n",
        "        acc_signal  = avg_signal(ts_cort, acc_idx)  if acc_idx else None\n",
        "        pcc_signal  = avg_signal(ts_cort, pcc_idx)  if pcc_idx else None\n",
        "        mpfc_signal = avg_signal(ts_cort, mpfc_idx) if mpfc_idx else None\n",
        "\n",
        "        def safe_corr(a,b):\n",
        "            if a is None or b is None: return np.nan\n",
        "            if np.all(np.isfinite(a)) and np.all(np.isfinite(b)):\n",
        "                if a.std()==0 or b.std()==0: return np.nan\n",
        "                return float(np.corrcoef(a,b)[0,1])\n",
        "            return np.nan\n",
        "\n",
        "        amyg_pfc  = safe_corr(amyg_signal, pfc_signal)\n",
        "        amyg_acc  = safe_corr(amyg_signal, acc_signal)\n",
        "        pcc_mpfc  = safe_corr(pcc_signal, mpfc_signal)\n",
        "\n",
        "        try:\n",
        "            conn = conn_estimator.fit_transform([ts_cort])[0]\n",
        "        except Exception as e:\n",
        "            print('Error computing connectome for', sub, e)\n",
        "            conn = None\n",
        "\n",
        "        clustering_coeff = modularity = global_eff = np.nan\n",
        "        if conn is not None:\n",
        "            M = conn.copy()\n",
        "            np.fill_diagonal(M,0)\n",
        "            M_thr = np.where(M>0.2, M, 0)\n",
        "            try:\n",
        "                G = nx.from_numpy_array(M_thr)\n",
        "                clustering_coeff = nx.average_clustering(G, weight='weight')\n",
        "                comms = list(nx.algorithms.community.greedy_modularity_communities(G, weight='weight'))\n",
        "                modularity = nx.algorithms.community.quality.modularity(G, comms, weight='weight')\n",
        "                global_eff = nx.global_efficiency(G)\n",
        "            except Exception as e:\n",
        "                print('Graph metric error for', sub, e)\n",
        "\n",
        "        pid = f'sub-{sub}'\n",
        "        lab = pheno.loc[pheno['participant_id']==pid, label_col].values\n",
        "        labv = lab[0] if len(lab)>0 else 'Unknown'\n",
        "\n",
        "        rows.append({\n",
        "            'Subject_ID': pid,\n",
        "            'Amygdala_Prefrontal_corr': np.round(amyg_pfc, 3) if not np.isnan(amyg_pfc) else np.nan,\n",
        "            'Amygdala_ACC_corr': np.round(amyg_acc, 3) if not np.isnan(amyg_acc) else np.nan,\n",
        "            'PCC_mPFC_corr': np.round(pcc_mpfc, 3) if not np.isnan(pcc_mpfc) else np.nan,\n",
        "            'Modularity': np.round(modularity, 3) if not np.isnan(modularity) else np.nan,\n",
        "            'ClusteringCoeff': np.round(clustering_coeff, 3) if not np.isnan(clustering_coeff) else np.nan,\n",
        "            'GlobalEfficiency': np.round(global_eff, 3) if not np.isnan(global_eff) else np.nan,\n",
        "            'Label': labv\n",
        "        })\n",
        "\n",
        "    df_out = pd.DataFrame(rows)\n",
        "    df_out.to_csv('secondary_dataset.csv', index=False, sep='\\t')\n",
        "    print(df_out.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hHvLj9DoJBZj"
      },
      "source": [
        "## Main function to run the whole script"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BY1gObHrJBBx"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "\n",
        "# ==================== MAIN ====================\n",
        "if __name__ == \"__main__\":\n",
        "    # Step 1: install dependencies (optional if already installed)\n",
        "    # install_requirements()\n",
        "\n",
        "    # Step 2: download dataset (optional if already present)\n",
        "    # download_dataset()\n",
        "\n",
        "    # Step 3: print fMRIPrep Docker command\n",
        "    print_fmriprep_command(\n",
        "        BIDS_DIR='ds002785',\n",
        "        OUT_DIR='derivatives/fmriprep',\n",
        "        WORK_DIR='fmriprep_work',\n",
        "        FS_LICENSE='~/.freesurfer/license.txt',\n",
        "        PARTICIPANTS=[] # e.g., ['01','02']\n",
        "    )\n",
        "\n",
        "    # Step 4: feature extraction (requires fMRIPrep outputs)\n",
        "    extract_features(\n",
        "        BIDS_DIR='ds002785',\n",
        "        DERIV_DIR='derivatives/fmriprep',\n",
        "        SPACE='MNI152NLin2009cAsym'\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "# **Deliverables 2** -\n",
        "\n",
        "\n",
        "* Python Notebook for classification models.\n",
        "* Documentation of methods and results.\n",
        "* Automated update pipeline.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "LbUC_hMsqLlJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing required packages and modules"
      ],
      "metadata": {
        "id": "AqeqcEBBqkch"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!/usr/bin/env python3\n",
        "# -*- coding: utf-8 -*-import os\n",
        "\n",
        "import json\n",
        "import joblib\n",
        "import glob\n",
        "import warnings\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import StratifiedKFold, cross_val_score, GridSearchCV, train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import (roc_auc_score, average_precision_score, precision_score, recall_score, f1_score,\n",
        "                             accuracy_score, balanced_accuracy_score, confusion_matrix, roc_curve, precision_recall_curve)\n",
        "from sklearn.calibration import calibration_curve, CalibratedClassifierCV\n",
        "from sklearn.inspection import permutation_importance\n",
        "import matplotlib.pyplot as plt\n",
        "import hashlib\n",
        "import time\n",
        "\n",
        "warnings.filterwarnings('ignore')  # Suppressing warnings for cleaner output\n",
        "RND = 42  # Random seed for reproducibility\n",
        "OUT_DIR = Path('hda7_outputs')  # Output directory for results and models\n",
        "OUT_DIR.mkdir(exist_ok=True)  # Create output directory if it doesn't exist"
      ],
      "metadata": {
        "id": "xR5el2ZDqGv1"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading the .csv created by extracting features"
      ],
      "metadata": {
        "id": "HxK3bVH7qyMC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_secondary(path='secondary_dataset.csv'):\n",
        "\n",
        "    # Detects delimiter automatically (tab or comma).\n",
        "    # Sets 'Subject_ID' column as index if present.\n",
        "    df = pd.read_csv(path, sep='\\t' if '\\t' in open(path).read(1000) else ',')\n",
        "    if 'Subject_ID' in df.columns:\n",
        "        df = df.set_index('Subject_ID')\n",
        "    return df"
      ],
      "metadata": {
        "id": "9WzHevs3qytI"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "   ## Standardize and binarize labels into 'Case' (1) and 'Control' (0)\n",
        "   ## Mapping done by searching keywords in label strings.\n",
        "   ## Raises error if label column missing.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Oc-fCAw9rBCG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def sanitize_labels(df, label_col='Label'):\n",
        "    if label_col not in df.columns:\n",
        "      raise ValueError('Label column missing')\n",
        "    df = df.copy()\n",
        "    df[label_col] = df[label_col].astype(str)\n",
        "    # Map labels containing 'social', 'case', or 'patient' to 'Case'\n",
        "    mapping = {k: 'Case' for k in df[label_col].unique() if 'social' in k.lower() or 'case' in k.lower() or 'patient' in k.lower()}\n",
        "    # Map labels containing 'control' or 'healthy' to 'Control'\n",
        "    mapping.update({k: 'Control' for k in df[label_col].unique() if 'control' in k.lower() or 'healthy' in k.lower()})\n",
        "    # Apply mapping; default to 'Control' if unmatched\n",
        "    df['y'] = df[label_col].map(lambda x: mapping.get(x, 'Control'))\n",
        "    df['y'] = (df['y'] == 'Case').astype(int)  # Convert to binary 0/1\n",
        "    return df\n"
      ],
      "metadata": {
        "id": "qzq8osI3rN8_"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " ## Extracting numeric features from Dataframe , dropping columns that are NaN or have null column names"
      ],
      "metadata": {
        "id": "osmtyQzbrSED"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_feature_table(df):\n",
        "    feats = df.select_dtypes(include=[np.number]).copy()\n",
        "    feats = feats.loc[:, feats.columns.notnull()]  # Drop columns with null names\n",
        "    feats = feats.dropna(axis=1, how='all')  # Drop columns that are all NaN\n",
        "    return feats"
      ],
      "metadata": {
        "id": "VkS2ADTkrQ65"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Split features and labels into train/test and perfroming Nested Cross-validation"
      ],
      "metadata": {
        "id": "7BU_fo8JrxFz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_test_split_subjectwise(X, y, test_size=0.2):\n",
        "\n",
        "    # Uses fixed random seed.\n",
        "    return train_test_split(X, y, test_size=test_size, stratify=y, random_state=RND)\n",
        "\n",
        "\n",
        "def nested_cv_evaluate(X, y, estimator, param_grid, cv_outer=5, cv_inner=3):\n",
        "\n",
        "    # Outer loop splits data for evaluation,\n",
        "    # Inner loop performs hyperparameter tuning via GridSearchCV.\n",
        "\n",
        "    # Returns list of dictionaries with performance metrics and best params per fold.\n",
        "\n",
        "    outer = StratifiedKFold(n_splits=cv_outer, shuffle=True, random_state=RND)\n",
        "    results = []\n",
        "    for train_idx, test_idx in outer.split(X, y):\n",
        "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
        "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
        "\n",
        "        # Pipeline: median imputation -> standard scaling -> classifier\n",
        "        pipe = Pipeline([\n",
        "            ('imputer', SimpleImputer(strategy='median')),\n",
        "            ('scaler', StandardScaler()),\n",
        "            ('clf', estimator)\n",
        "        ])\n",
        "\n",
        "        # Hyperparameter tuning with inner CV, scoring by ROC AUC\n",
        "        gs = GridSearchCV(pipe, param_grid, cv=cv_inner, scoring='roc_auc', n_jobs=-1)\n",
        "        gs.fit(X_train, y_train)\n",
        "\n",
        "        best = gs.best_estimator_\n",
        "\n",
        "        # Get predicted probabilities or decision function scores\n",
        "        probas = best.predict_proba(X_test)[:,1] if hasattr(best, 'predict_proba') else best.decision_function(X_test)\n",
        "        preds = best.predict(X_test)\n",
        "\n",
        "        # Store metrics and predictions for this fold\n",
        "        res = {\n",
        "            'best_params': gs.best_params_,\n",
        "            'roc_auc': roc_auc_score(y_test, probas),\n",
        "            'pr_auc': average_precision_score(y_test, probas),\n",
        "            'accuracy': accuracy_score(y_test, preds),\n",
        "            'balanced_acc': balanced_accuracy_score(y_test, preds),\n",
        "            'precision': precision_score(y_test, preds, zero_division=0),\n",
        "            'recall': recall_score(y_test, preds, zero_division=0),\n",
        "            'f1': f1_score(y_test, preds, zero_division=0),\n",
        "            'y_test': y_test.values.tolist(),\n",
        "            'y_score': probas.tolist(),\n",
        "            'y_pred': preds.tolist()\n",
        "        }\n",
        "        results.append(res)\n",
        "    return results"
      ],
      "metadata": {
        "id": "tylRJJsYruSi"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Aggregate cross-validation results by computing mean and std for each metric across folds."
      ],
      "metadata": {
        "id": "G0GUrHvwsJzn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def aggregate_results(cv_results):\n",
        "\n",
        "    metrics = ['roc_auc','pr_auc','accuracy','balanced_acc','precision','recall','f1']\n",
        "    agg = {}\n",
        "    for m in metrics:\n",
        "        vals = [r[m] for r in cv_results]\n",
        "        agg[m+'_mean'] = float(np.mean(vals))\n",
        "        agg[m+'_std'] = float(np.std(vals))\n",
        "    return agg"
      ],
      "metadata": {
        "id": "lK-1zof3sKDn"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training the final model on the entire dataset using provided hyperparameters\n",
        "## Compute permutation feature importance for trained model."
      ],
      "metadata": {
        "id": "un_indcFsX1N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def train_final_model(X, y, estimator, params):\n",
        "\n",
        "\n",
        "    # Applies median imputation and standard scaling in pipeline.\n",
        "\n",
        "    pipe = Pipeline([\n",
        "        ('imputer', SimpleImputer(strategy='median')),\n",
        "        ('scaler', StandardScaler()),\n",
        "        ('clf', estimator)\n",
        "    ])\n",
        "    # Set classifier params (strip 'clf__' prefix if present)\n",
        "    pipe.set_params(**{f'clf__{k}': v for k,v in params.items() if k.replace('clf__','')!=k})\n",
        "    pipe.fit(X, y)\n",
        "    return pipe\n",
        "\n",
        "\n",
        "def permutation_imp(model, X, y, n_repeats=30):\n",
        "\n",
        "   # Returns DataFrame sorted by importance.\n",
        "    imp = permutation_importance(model, X, y, n_repeats=n_repeats, random_state=RND, n_jobs=-1)\n",
        "    fi = pd.DataFrame({\n",
        "        'feature': X.columns,\n",
        "        'importance_mean': imp.importances_mean,\n",
        "        'importance_std': imp.importances_std\n",
        "    })\n",
        "    fi = fi.sort_values('importance_mean', ascending=False)\n",
        "    return fi"
      ],
      "metadata": {
        "id": "BgmIdCxDsW2U"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plotting various metrics and saving it in json files"
      ],
      "metadata": {
        "id": "-sna_XvYsqFv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_roc_pr(y_test, y_score, out_prefix):\n",
        "\n",
        "    # Plot and save ROC curve and Precision-Recall curve.\n",
        "\n",
        "    fpr, tpr, _ = roc_curve(y_test, y_score)\n",
        "    precision, recall, _ = precision_recall_curve(y_test, y_score)\n",
        "\n",
        "    plt.figure()\n",
        "    plt.plot(fpr, tpr)\n",
        "    plt.xlabel('FPR')\n",
        "    plt.ylabel('TPR')\n",
        "    plt.title('ROC')\n",
        "    plt.savefig(f'{out_prefix}_roc.png')\n",
        "    plt.close()\n",
        "\n",
        "    plt.figure()\n",
        "    plt.plot(recall, precision)\n",
        "    plt.xlabel('Recall')\n",
        "    plt.ylabel('Precision')\n",
        "    plt.title('PR')\n",
        "    plt.savefig(f'{out_prefix}_pr.png')\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "def plot_calibration(y_true, y_prob, out_path):\n",
        "\n",
        "    # Plot calibration curve comparing predicted probabilities to observed frequencies.\n",
        "\n",
        "    prob_true, prob_pred = calibration_curve(y_true, y_prob, n_bins=10)\n",
        "    plt.figure()\n",
        "    plt.plot(prob_pred, prob_true, marker='o')\n",
        "    plt.plot([0,1],[0,1],'--')  # Reference line for perfect calibration\n",
        "    plt.xlabel('Predicted probability')\n",
        "    plt.ylabel('True probability')\n",
        "    plt.title('Calibration')\n",
        "    plt.savefig(out_path)\n",
        "    plt.close()\n",
        "\n",
        "\n",
        "def ablation_study(df, y, feature_groups):\n",
        "\n",
        "    # Perform ablation study by training models on different feature subsets.\n",
        "    # Uses RandomForestClassifier with nested CV.\n",
        "    # Returns DataFrame with aggregated performance per feature group.\n",
        "\n",
        "    ablation_results = []\n",
        "    for name, cols in feature_groups.items():\n",
        "        X_sub = df[cols].copy()\n",
        "        X_sub = X_sub.select_dtypes(include=[np.number])\n",
        "        X_sub = X_sub.fillna(X_sub.median())  # Fill missing values with median\n",
        "\n",
        "        est = RandomForestClassifier(random_state=RND)\n",
        "        params = {'clf__n_estimators':[100], 'clf__max_depth':[5,10]}\n",
        "        res = nested_cv_evaluate(X_sub, y, est, params, cv_outer=5, cv_inner=3)\n",
        "        agg = aggregate_results(res)\n",
        "        agg['group'] = name\n",
        "        ablation_results.append(agg)\n",
        "    return pd.DataFrame(ablation_results)\n",
        "\n",
        "\n",
        "def save_json(obj, path):\n",
        "\n",
        "    # Save a Python object as a pretty-printed JSON file.\n",
        "\n",
        "    with open(path,'w') as f:\n",
        "        json.dump(obj, f, indent=2)"
      ],
      "metadata": {
        "id": "uT89nxc7smtn"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Main Pipeline Function"
      ],
      "metadata": {
        "id": "9cBgX5BTs_V4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def compute_file_hash(path):\n",
        "    # Compute MD5 hash of a file for change detection.\n",
        "\n",
        "    h = hashlib.md5()\n",
        "    with open(path,'rb') as f:\n",
        "        while chunk := f.read(8192):\n",
        "            h.update(chunk)\n",
        "    return h.hexdigest()\n",
        "\n",
        "\n",
        "def run_pipeline(secondary_path='secondary_dataset.csv'):\n",
        "    \"\"\"\n",
        "    Run the full pipeline end-to-end:\n",
        "    - Load and sanitize data\n",
        "    - Extract features and labels\n",
        "    - Split data into train/test\n",
        "    - Train and evaluate multiple classifiers with nested CV\n",
        "    - Save CV results and aggregate metrics\n",
        "    - Train final model with best parameters\n",
        "    - Evaluate final model on test set and save metrics, plots\n",
        "    - Compute feature importances and perform ablation study\n",
        "    - Save comprehensive report with metadata and file hash\n",
        "    \"\"\"\n",
        "    df = load_secondary(secondary_path)\n",
        "    df = sanitize_labels(df, label_col='Label')\n",
        "    feats = build_feature_table(df)\n",
        "    y = df['y']\n",
        "    feat_cols = feats.columns.tolist()\n",
        "\n",
        "    # Split into train/test sets stratified by label\n",
        "    X_train, X_test, y_train, y_test = train_test_split_subjectwise(feats, y, test_size=0.2)\n",
        "\n",
        "    # Define classifiers to evaluate\n",
        "    estimators = {\n",
        "        'logreg': LogisticRegression(max_iter=1000, solver='liblinear'),\n",
        "        'rf': RandomForestClassifier(random_state=RND),\n",
        "        'svc': SVC(probability=True, random_state=RND)\n",
        "    }\n",
        "\n",
        "    # Hyperparameter grids for each classifier\n",
        "    param_grids = {\n",
        "        'logreg': {'clf__C':[0.01,0.1,1,10]},\n",
        "        'rf': {'clf__n_estimators':[100,200], 'clf__max_depth':[5,10,None]},\n",
        "        'svc': {'clf__C':[0.1,1,10], 'clf__kernel':['rbf','linear']}\n",
        "    }\n",
        "\n",
        "    # Nested CV for each estimator; save results and summary\n",
        "    all_cv_results = {}\n",
        "    for name, est in estimators.items():\n",
        "        res = nested_cv_evaluate(feats, y, est, param_grids[name], cv_outer=5, cv_inner=3)\n",
        "        agg = aggregate_results(res)\n",
        "        all_cv_results[name] = agg\n",
        "        save_json(res, OUT_DIR/f'cv_results_{name}.json')\n",
        "    save_json(all_cv_results, OUT_DIR/'cv_summary.json')\n",
        "\n",
        "    # Select best model based on mean ROC AUC\n",
        "    best_model_name = max(all_cv_results.items(), key=lambda x: x[1]['roc_auc_mean'])[0]\n",
        "    best_params = json.load(open(OUT_DIR/f'cv_results_{best_model_name}.json'))[0]['best_params']\n",
        "    best_estimator = estimators[best_model_name]\n",
        "\n",
        "    # Train final model on full dataset with best params\n",
        "    fitted = train_final_model(feats, y, best_estimator, {k.replace('clf__',''):v for k,v in best_params.items()})\n",
        "    joblib.dump(fitted, OUT_DIR/f'final_model_{best_model_name}.joblib')\n",
        "\n",
        "    # Evaluate final model on holdout test set\n",
        "    X_test_filled = X_test.fillna(X_test.median())  # Fill missing values in test set\n",
        "    y_proba = fitted.predict_proba(X_test_filled)[:,1]\n",
        "    y_pred = fitted.predict(X_test_filled)\n",
        "    metrics = {\n",
        "        'roc_auc': float(roc_auc_score(y_test, y_proba)),\n",
        "        'pr_auc': float(average_precision_score(y_test, y_proba)),\n",
        "        'accuracy': float(accuracy_score(y_test, y_pred)),\n",
        "        'balanced_acc': float(balanced_accuracy_score(y_test, y_pred)),\n",
        "        'precision': float(precision_score(y_test, y_pred, zero_division=0)),\n",
        "        'recall': float(recall_score(y_test, y_pred, zero_division=0)),\n",
        "        'f1': float(f1_score(y_test, y_pred, zero_division=0))\n",
        "    }\n",
        "    save_json(metrics, OUT_DIR/'final_test_metrics.json')\n",
        "\n",
        "    # Plot ROC and PR curves\n",
        "    plot_roc_pr(y_test, y_proba, OUT_DIR/f'final_{best_model_name}')\n",
        "    # Plot calibration curve\n",
        "    plot_calibration(y_test, y_proba, OUT_DIR/f'calibration_{best_model_name}.png')\n",
        "\n",
        "    # Compute and save permutation feature importance\n",
        "    fi = permutation_imp(fitted, feats, y)\n",
        "    fi.to_csv(OUT_DIR/'permutation_importance.csv', index=False)\n",
        "\n",
        "    # Define feature groups for ablation study\n",
        "    feature_groups = {\n",
        "        'amygdala_only':[c for c in feat_cols if 'Amygdala' in c or 'amyg' in c.lower()],\n",
        "        'connectome_graph':['Modularity','ClusteringCoeff','GlobalEfficiency'],\n",
        "        'all':feat_cols\n",
        "    }\n",
        "    ablation = ablation_study(feats, y, feature_groups)\n",
        "    ablation.to_csv(OUT_DIR/'ablation_results.csv', index=False)\n",
        "\n",
        "    # Save run summary report with metadata and file hash for reproducibility\n",
        "    report = {\n",
        "        'run': 'hda7 full pipeline',\n",
        "        'random_seed': RND,\n",
        "        'best_model': best_model_name,\n",
        "        'metrics': metrics,\n",
        "        'timestamp': time.strftime('%Y-%m-%d %H:%M:%S'),\n",
        "        'file_hash': compute_file_hash(secondary_path)\n",
        "    }\n",
        "    save_json(report, OUT_DIR/'report_summary.json')\n",
        "\n",
        "\n",
        "def automated_update_pipeline(secondary_path='secondary_dataset.csv'):\n",
        "\n",
        "    # Detect if the input dataset has changed by comparing file hashes.\n",
        "    # If changed, run the full pipeline and update state file.\n",
        "    # Otherwise, skip re-running the pipeline.\n",
        "\n",
        "    state_file = OUT_DIR/'last_run.json'\n",
        "    new_hash = compute_file_hash(secondary_path)\n",
        "    old_hash = None\n",
        "    if state_file.exists():\n",
        "        old_state = json.load(open(state_file))\n",
        "        old_hash = old_state.get('file_hash')\n",
        "    if new_hash != old_hash:\n",
        "        print(\"Detected change in dataset. Running full pipeline...\")\n",
        "        run_pipeline(secondary_path)\n",
        "        save_json({'file_hash': new_hash, 'timestamp': time.strftime('%Y-%m-%d %H:%M:%S')}, state_file)\n",
        "    else:\n",
        "        print(\"No changes in dataset. Skipping re-run.\")"
      ],
      "metadata": {
        "id": "40oM9IhLs7ly"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nOgMUGAEp0zR",
        "outputId": "11320976-b218-4960-c099-578fc069f391"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detected change in dataset. Running full pipeline...\n"
          ]
        }
      ],
      "source": [
        "automated_update_pipeline('secondary_dataset.csv')\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}